<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">

#* Validation output page

$VM -- Instance of ValidationBase 
*#

#from mscanner.configuration import rc

#set $vectors = $VM.metric_vectors  ## PerformanceVectors instance
#set $range = $VM.metric_range      ## PerformanceRanges instance
#set $t = $VM.metric_range.average  ## PerformanceMetrics instance

<html lang="en">

<head>

  <title>MScanner validation results: $VM.dataset</title>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">

  #if $rc.link_headers
  ## Link to original JS and CSS instead of including them
  #set $linkpath = $rc.templates.relpath().replace('\\','/')
  <script type="text/javascript" src="$linkpath/hider.js"></script>
  <link rel="stylesheet" type="text/css" href="$linkpath/style.css">
  #else

  <script type="text/javascript">
    #include raw str($rc.templates/"hider.js")
  </script>

  <style type="text/css">
    #include raw str($rc.templates/"style.css")
  </style>
  #end if
  
  <script type="text/javascript">
  window.onload = function() { make_toggles(); }
  </script>
  
</head>

#def help(name)
<td>
  #if $name is not None
  <button class="toggle" id="toggle_$name">?</button>
  #end if
</td>
#end def

#def hr(name, value)
<tr id="$name" class="help">
  <td colspan="3">
    $value
  </td>
</tr>
#end def

<body>

<div id="header">
 <h1>MScanner validation results: $VM.dataset</h1>
</div>

<div id="body">

<div class="narrow">

<h2>Global information</h2>

<table class="results">

  <colgroup>
    <col class="label">
    <col class="value">
    <col class="help">
  </colgroup>

  <tr>
    <td>Timestamp</td>
    #import time
    <td>$time.strftime("%Y/%m/%d %H:%M:%S GMT", $time.gmtime($VM.timestamp))</td>
    $help("h_timestamp")
  </tr>
  $hr("h_timestamp", """Date and time at which the query was submitted.""")

  <tr>
    <td>Feature score table</td>
    <td>
    ##<a href="$rc.report_term_scores_zip">ZIP file</a> or 
    <a href="$rc.report_term_scores">$rc.report_term_scores</a>
    </td>
    $help("h_csv")
  </tr>
  $hr("h_csv", """CSV spreadsheet detailing the calculation of 
  the feature support scores.""")

  <tr>
    <td>Relevant PubMed IDs</td>
    <td><a href="$rc.report_positives">$rc.report_positives</a></td>
    $help("h_positives")
  </tr>
  $hr("h_positives", """List of PubMed IDs of the relevant training
  examples.  Dividing the file into 10 parts yields the cross
  validation folds.""")

  <tr>
    <td>Irrelevant PubMed IDs</td>
    <td><a href="$rc.report_negatives">$rc.report_negatives</a></td>
    $help("h_negatives")
  </tr>
  $hr("h_negatives", """List of PubMed IDs of the irrelevant 
  examples (randomly sampled from Medline).  Dividing the file into 10 
  parts yields the cross validation folds.""")

  <tr class="newsection">
    <td>Number of folds</td>
    <td>$range.nfolds</td>
    $help("h_nfolds")
  </tr>
  $hr("h_nfolds", """Number of partitions into which the relevant
  and irrelevant data sets were split.""")

  <tr>
    <td>Prior score</td>
    <td>$VM.featinfo.prior</td>
    $help("h_prior")
  </tr>
  $hr("h_prior", """The log ratio of relevant to irrelevant articles
  in the cross validation data.  This prior log ratio is added to 
  log likelihood ratios to obtain posterior article scores.""") 

  <tr>
    <td>Base score</td>
    <td>$VM.featinfo.base</td>
    $help("h_base")
  </tr>
  $hr("h_base", """The log likelihood ratio of an empty article (one in 
  which every feature failed to occur).""") 

  <tr class="newsection">
    <td>Average Precision</td>
    <td>#echo "%.5f" % $vectors.AvPrec #</td>
    $help("h_avprec")
  </tr>
  $hr("h_avprec", """Precision averaged over all ranks where
  an article is retrieved.""")
  
  <tr class="newsection">
    <td>Area under ROC curve (AUC)</td>
    <td>#echo "%.5f" % $vectors.W #</td>
    $help("h_roc")
  </tr>
  $hr("h_roc", """Area under the graph of the true
  positive rate versus false positive rate.  Equals the probability
  that a randomly selected relevant article will be ranked above
  a randomly selected irrelevant article.""")

  <tr>
    <td>Standard Error of AUC</td>
    <td>#echo "%.5f" % $vectors.W_stderr #</td>
    $help("h_roc_stderr")
  </tr>
  $hr("h_roc_stderr", """Standard error of the area
  under the ROC curve.  Calculated using the method of Hanley (1982).""")

</table>

#if not $hasattr($VM, "pred_low")

<div>
  <h2>Confusion Matrix at threshold
  <button class="toggle" id="toggle_h_cmatrix">?</button>
  </h2>

  <div class="help" id="h_cmatrix">
  <p>The columns of the confusion matrix are actual categories of the
  documents, and the rows are the predicted categories. Hover the mouse over
  each of the squares for a full description of the quantity, and the formula
  for calculating it.</p> 
  </div>

  <table id="matrix">
    <tr>
      <th rowspan="2" colspan="2"></th>
      <th colspan="2">Actual</th>
      <th rowspan="2">Totals</th>
      <th rowspan="2">Rates</th>
    </tr>
    <tr>
      <th>Relevant</th>
      <th>Irrelevant</th>
    </tr>
    <tr>
      <th rowspan="2">Predicted</th>
      <th>Relevant'</th>
      <td class="tp" title="True Positives (hits)">TP=$t.TP</td>  
      <td class="fp" title="False Positives (false alarms / Type I errors)">FP=$t.FP</td>
      <td title="Positive predictions = TP+FP">P'=#echo $t.TP+$t.FP#</td>
      <td title="Positive Predictive Value = TP/(TP+FP)">PPV=#echo "%.2f"%$t.PPV#</td>
    </tr>
    <tr>
      <th>Irrelevant'</th>
      <td class="fn" title="False Negatives (misses / Type II errors)">FN=$t.FN</td>
      <td class="tn" title="True Negatives (correct rejections)">TN=$t.TN</td>
      <td title="Negative predictions = TN+FN">N'=#echo $t.TN+$t.FN#</td>
      <td title="Negative Predictive Value = TN/(TN+FN)">NPV=#echo "%.5f"%t.NPV#</td>
    </tr>
    <tr>
      <th colspan="2">Totals</th>
      <td title="Positives = TP+FN">P=$t.P</td>
      <td title="Negatives = TN+FP">N=$t.N</td>
      <td title="Size of data = TP+TN+FP+FN">$t.A</td>
      <td title="Prevalence = (TP+FN)/(TP+TN+FP+FN)">Prev=#echo "%.5f"%$t.prevalence#</td>
    </tr>
    <tr>
      <th colspan="2">Rates</th>
      <td title="True Positive Rate (hit rate OR recall OR sensitivity) = TP/(TP+FN)">TPR=#echo "%.2f"%$t.TPR#</td>  
      <td title="False Positive Rate = FP/(TN+FP)">FPR=#echo "%.5f"%$t.FPR#</td>
      <td title="This square is intentionally left blank"></td>
      <td title="Accuracy = (TP+TN)/(TP+TN+FP+FN)">Acc=#echo "%.5f"%t.accuracy#</td> 
    </tr>
  </table>
</div>

<div>
  <h2>Precision, Recall and F measure</h2>

  <table class="results">
    <colgroup>
      <col class="longlabel">
      <col class="value">
      <col class="help">
    </colgroup>

    <tr>
      <td>Score threshold</td>
      <td>#echo "%.2f" % $range.threshold #</td>
      $help("h_threshold")
    </tr>
    $hr("h_threshold", """Articles with log probability ratio 
    scores higher than this are predicted positive.  Either the closest
    article score to zero is used, or we chose a threshold to
    maximise F score or Utility (which is the case if we achieve
    the F score or Utility maxima mentioned below).""")
  
    <tr>
      <td><b>Precision (PPV)</b> 
      <span class="footnote">&pi;=TP/(TP+FP)</span></td>
      <td>$range.fmt_stats("precision")</td>
      $help("h_prec")
    </tr>
    $hr("h_prec", """Proportion of predicted positives which are true
    positives.""")
    
    <tr>
    <td><b>Recall (True Positive Rate / Sensitivity)</b></td>
    <td>$range.fmt_stats("recall")</td>
    $help("h_recall")
    </tr>
    $hr("h_recall", """Proportion of positives which were correctly predicted
    to be positive.""")
    
    <tr>
      <td><b>F<sub>1</sub>-Measure (&alpha;=0.5)</b> 
      <span class="footnote">(2*&rho;*&pi;/(&rho;+&pi;))</span></td>
      <td>$range.fmt_stats("fmeasure")</td>
      $help("h_f1")
    </tr>
    $hr("h_f1", """Harmonic mean of recall and precision at the threshold
    corresponding to the maximum &alpha;-weighted F-Measure.""")
      
    <tr>
      <td><b>F-Measure (&alpha;=$vectors.alpha)</b> 
      <span class="footnote">(1/(&alpha;/&pi;+(1-&alpha;)/&rho;))</span></td>
      <td>$range.fmt_stats("fmeasure_alpha")</td>
      $help("h_fma")
    </tr>
    $hr("h_fma", """The F measure evaluated using
    the given alpha. 0 &lt;= &alpha; &lt;= 1 controls the weight of
    precision. When &alpha;=0.5, <em>F=F<sub>1</sub></em>.""")
    
    <tr>
      <td><b>Maximum possible F<sub>1</sub>-Measure</b></td>
      <td>#echo "%.3f" % $vectors.FM.max() #</td>
      $help("h_max_f1")
    </tr>
    $hr("h_max_f1", """This is the F_1 measure that would be achieved if we
    had set &alpha;=0.5""")
    
    <tr class="newsection">
      <td><b>Break-Even</b> <span class="footnote">(where precision=recall)</span></td>
      <td>#echo "%.3f" % $vectors.breakeven #</td>
      $help("h_break_even")
    </tr>
    $hr("h_break_even", """Shared value at the point where Recall = Precision =
    F1-measure. Typically the F1-Measure at break-even is slightly lower than the
    maximum F1-Measure.""")

  </table>
</div>

<div>
  <h2>Utility
  <button class="toggle" id="toggle_h_utility">?</button>
  </h2>

  <div class="help" id="h_utility">
  <p>Utility is a weighted sum of True and False positives. A false
  positive has utility -1, and a true positive has utility u<sub>r</sub>,
  by default equal to N/P (the assumption being that returning all the
  articles should result in utility of zero).</p>
  
  <p>Hence, <tt>U = (u<sub>r</sub> * TP - FP)/U<sub>max</sub></tt> where
  <tt>U<sub>max</sub> = u<sub>r</sub> * P</tt> is the maximium achievable
  utility. If u<sub>r</sub> defaults to N/P this reduces to
  <tt>U=(TP/P)-(FP/N)</tt>.</p>
  </div>

  <table class="results">
    <colgroup>
      <col class="longlabel">
      <col class="value">
    </colgroup>
    <tr>
      <td><b>Utility (u<sub>r</sub>=#echo "%.2f" % $vectors.utility_r #</b>)</td>
      <td>$range.fmt_stats("utility")</td>
    </tr>
    <tr>
      <td><b>Maximum possible utility</td>
      <td>#echo "%.3f" % $vectors.U.max() #</td>
    </tr>
  </table>
</div>

<div>
  <h2>Miscellaneous Performance Measures</h2>

  <table class="results">
    <colgroup>
      <col class="longlabel">
      <col class="value">
      <col class="help">
    </colgroup>

    <tr>
      <td><b>Prevalence in cross validation</b> 
      <span class="footnote">P/(P+N)</span></td>
      <td>#echo "%.5f" % $t.prevalence #</td>
      $help("h_prevalence")
    </tr>
    $hr("h_prevalence", """Proportion of training data which was positive.""")
    
    <tr>
      <td><b>False Positive Rate (FPR)</b> 
      <span class="footnote">FPR=FP/(TN+FP)=1-TNR</span></td>
      <td>$range.fmt_stats("FPR", places=5)</td>
      $help("h_fpr")
    </tr>
    $hr("h_fpr", """Proportion of negatives which were incorrectly predicted
    to be positive.""")
    
    <tr>
      <td><b>Specificity (TNR)</b> 
      <span class="footnote">TNR=TN/(TN+FP)=1-FPR</span></td>
      <td>$range.fmt_stats("specificity", places=5)</td>
      $help("h_specificity")
    </tr>
    $hr("h_specificity", """Proportion of negatives which were correctly
    predicted to be negative.""")

    <tr>
      <td><b>Error Rate</b> 
      <span class="footnote">(FP+FN)/(P+N)=1-Accuracy</span></td>
      <td>$range.fmt_stats("error", places=5)</td>
      <td></td>
    </tr>

    <tr>
      <td><b>Enrichment</b> 
      <span class="footnote">(= precision/prevalence)</span></td>
      <td>$range.fmt_stats("enrichment")</td>
      $help("h_enrich")
    </tr>
    $hr("h_enrich", """Precision over prevalence. This is is how much better this
    classifiers precision is over a classifier which calls everything positive.""")

  </table> 
</div>

#end if cross validation results


<div>
#set global $stats = $VM.featinfo.stats
#include str($rc.templates/"features.tmpl")
</div>


<div>
  <h2>Performance graphs</h2>

  #if $hasattr($VM, "pred_low")
  <div><h3>Predicted performance</h3>
    
    <p>We predict recall and precision as a function of rank
    in a retrieval situation (whole-Medline) for two values of prevalence
    (fraction of Medline that is relevant)  We assume there are between
    ${VM.pred_low.relevant} and ${VM.pred_high.relevant} relevant records 
    remaining in Medline (which has ${VM.pred_low.total} records).  We
    use true and false positive rates to estimate the number of true
    and false positives at each rank.</p>
    
    <img src="$rc.report_prediction_img" alt="Predicted precision"/>
  </div>
  #end if query prediction graph


  <div><h3>Document score distributions</h3>
    <p>Normalised histograms (sum of bar areas normalised to 1), approximating
    probability distributions for relevant and irrelevant article scores. Good
    performance is associated with clean separation of the distributions.</p>
    <img src="$rc.report_artscores_img" alt="Article score distributions"/>
  </div>


  <div><h3>Feature score distribution</h3>
    <p>Normalised histogram approximating the probability distribution
    for feature feature scores (after training on all available data).</p>
    <img src="$rc.report_featscores_img" alt="Feature score distribution"/>
  </div>

#if not hasattr($VM, "pred_low")
  <div><h3>ROC Curve</h3>
    <p>True Positive Rate versus False Positive Rate.  The closer
    to the top left the curve gets, the better. Worst case is a diagonal
    line (true positives increasing at the same rate as false
    positives).</p>
    <img src="$rc.report_roc_img" alt="ROC Curve"/>
  </div>
  
  
  <div><h3>Precision-Recall Curve</h3>
    <p>Precision as a function of Recall.  The recall corresponding
    to the chosen threshold is marked with a vertical line. 
    Worst case is a horizontal line at the level of prevalence.</p>
    <img src="$rc.report_prcurve_img" alt="Precision-Recall Curve"/>
  </div>

  <div><h3>F measure versus threshold</h3>
    <p>Precision, Recall and F-measure as a function of threshold.
    The chosen threshold is marked with a vertical line.</p>
    <img src="$rc.report_fmeasure_img" alt="Precision and Recall vs Threshold"/>
  </div>
#end if cross validation results

</div>

<div>
#set $notfound_pmids = $VM.notfound_pmids
#include str($rc.templates/"invalid.tmpl")
</div>

</div><!--narrow-->

</div><!--body-->

<div id="footer">
  MScanner &copy; 2007 Graham Poulter
</div>

</body>
</html>